{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train/Test split files for Caffe\n",
    "\n",
    "Need to create two files, train.txt and test.txt, that list out the image files for each set and their 0/1 labels (0 == negative, 1 == positive).  In our case, positive means \"relevant for HT investigation\".\n",
    "\n",
    "In reality, we create train and test listings that contain equal numbers of positive and negative examples. This is to eliminate any class biasing that may occur when training. For example, if ~70% of examples were negative, the CNN may train to call everything negative, thus yielding a ~70% accuracy. This is clearly not desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__depends__ = [\n",
    "    'image_path_to_sha1.csv',\n",
    "    'train_pos_shas.pickle',\n",
    "    'test_pos_shas.pickle',\n",
    "    'train_neg_shas.pickle',\n",
    "    'test_neg_shas.pickle',\n",
    "]\n",
    "__dest__ = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV of image path to its SHA1 checksum\n",
    "# - should only list valid image files that Caffe can load\n",
    "IMAGE_PATH_TO_SHA1 = \"image_path_to_sha1.csv\"\n",
    "# Input sets of SHAs for train/test split\n",
    "TRAIN_POS_SHA1S = 'train_pos_shas.pickle'\n",
    "TRAIN_NEG_SHA1S = 'train_neg_shas.pickle'\n",
    "TEST_POS_SHA1S = 'test_pos_shas.pickle'\n",
    "TEST_NEG_SHA1S = 'test_neg_shas.pickle'\n",
    "# Output files for training with Caffe\n",
    "RAW_TRAIN_TXT = 'alexnet_adam/caffe.train.txt'\n",
    "RAW_TEST_TXT = 'alexnet_adam/caffe.test.txt'\n",
    "EVEN_TRAIN_TXT = 'alexnet_adam/caffe.even.train.txt'\n",
    "EVEN_TEST_TXT = 'alexnet_adam/caffe.even.test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mapping of SHA1 value to the path of the original image file\n",
    "sha2path = dict((r[1],r[0]) for r in csv.reader(open(IMAGE_PATH_TO_SHA1)))\n",
    "\n",
    "train_pos_shas = cPickle.load(open(TRAIN_POS_SHA1S))\n",
    "train_neg_shas = cPickle.load(open(TRAIN_NEG_SHA1S))\n",
    "test_pos_shas  = cPickle.load(open(TEST_POS_SHA1S))\n",
    "test_neg_shas  = cPickle.load(open(TEST_NEG_SHA1S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write raw train/test files\n",
    "#\n",
    "# Remember:\n",
    "#   0 == negative\n",
    "#   1 == positive\n",
    "with open(RAW_TRAIN_TXT, 'w') as f:\n",
    "    for sha in train_pos_shas:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in train_neg_shas:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 0\\n')\n",
    "\n",
    "with open(RAW_TEST_TXT, 'w') as f:\n",
    "    for sha in test_pos_shas:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in test_neg_shas:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output test and train sets with equal balance, randomly sub-sampling where needed\n",
    "even_train_size = min([len(train_pos_shas), len(train_neg_shas)])\n",
    "even_test_size = min([len(test_pos_shas), len(test_neg_shas)])\n",
    "\n",
    "print \"Even train size:\", even_train_size\n",
    "print \"Even test size :\", even_test_size\n",
    "\n",
    "random.seed(0)\n",
    "even_train_pos = random.sample(train_pos_shas, even_train_size)\n",
    "even_train_neg = random.sample(train_neg_shas, even_train_size)\n",
    "even_test_pos = random.sample(test_pos_shas, even_test_size)\n",
    "even_test_neg = random.sample(test_neg_shas, even_test_size)\n",
    "\n",
    "with open(EVEN_TRAIN_TXT, 'w') as f:\n",
    "    for sha in even_train_pos:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in even_train_neg:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 0\\n')\n",
    "\n",
    "with open(EVEN_TEST_TXT, 'w') as f:\n",
    "    for sha in even_test_pos:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 1\\n')\n",
    "    for sha in even_test_neg:\n",
    "        fp = sha2path[sha]\n",
    "        f.write(fp + ' 0\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Caffe training\n",
    "\n",
    "To start model fine-tuning:\n",
    "\n",
    "    caffe/build/tools/caffe train -sigint_effect snapshot -solver solver.prototxt -weights <base_model>\n",
    "    \n",
    "If already started and resuming from a snapshot is desired:\n",
    "\n",
    "    caffe/build/tools/caffe train -sigint_effect snapshot -solver solver.prototxt -snapshot <snapshot_file>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
